#!/usr/bin/env python
# -*- coding: utf-8 -*-

"""

Shows job information, like qstat, but customised for jobs on the local
cluster. Shows all user jobs by default, use the '--user' argument to
specify a user or list of users to show jobs for.

"""

from __future__ import print_function, division
import argparse
import re
import signal
import sys
from datetime import datetime
from getpass import getuser
from os.path import dirname, realpath

from dateutil.parser import parse

# Put the parent directory first in the path
sys.path.insert(1, dirname(dirname(realpath(__file__))))
from wslurm.sqstat import sinfof, squeuef
from wslurm.sqstat import sinfof_local, squeuef_local

# If output goes into head or less without finishing, it will terminate with
# IOError, this makes pipe errors get ignored.
signal.signal(signal.SIGPIPE, signal.SIG_DFL)


def commandline():
    """Process commandline options in here. Return the argparse object."""
    parser = argparse.ArgumentParser(description=__doc__)
    parser.add_argument("-u", "--user", nargs='+',
                        help="User or list of users to show jobs for. Names "
                        "may use regular expressions for wildcard matches.")
    parser.add_argument("-q", "--queue", action='store_true',
                        help="Show queue name in addition to the node name.")
    parser.add_argument("-f", "--full", action='store_true',
                        help="Show full output by nodes, like 'qstat -f'.")
    parser.add_argument("-n", "--no-colour", "--no-color", dest='colour',
                        action="store_false", help="Turn off coloured output.")
    options = parser.parse_args()

    return options


class ColourDict(dict):
    """
    Store items as colourised versions of themselves, changing the colour
    for each new item.
    """
    def __init__(self, width=12, mapping=None):
        self.width = width
        super(ColourDict, self).__init__(self)
        if mapping is not None:
            self.update(mapping)

    def __missing__(self, key):
        if not hasattr(self, 'counter'):
            self.counter = 1
        self[key] = "\033[38;5;{colour_id}m{key:<{width}}\033[0m".format(
            colour_id=self.counter, key=key, width=self.width)
        self.counter += 1
        return self[key]


class AutoDict(dict):
    """
    Add the missing entries as themselves to a dictionary.
    """
    def __init__(self, width=12):
        self.width = width
        super(AutoDict, self).__init__(self)

    def __missing__(self, key):
        self[key] = "{key:<{width}}".format(key=key, width=self.width)
        return self[key]


def parse_number(number):
    """
    Grok the value of the number from a string, deals with the M, G that appear
    in sge.

    """
    suffixes = {
        'K': 1024,
        'M': 1024**2,
        'G': 1024**3,
        'T': 1024**4}

    if isinstance(number, (int, float)):
        return number

    if '.' in number:
        fstr = re.search(r'-?(\d+(\.\d*)?|\.\d+)([eE][+-]?\d+)?', number)
        value = float(fstr.group())
    else:
        istr = re.search(r'-?\d+', number)
        value = int(istr.group())

    for suffix, multiplier in suffixes.items():
        if suffix in number:
            value *= multiplier

    return value


def progressbar(value, maximum, width=12, show_value=True, colour=True,
                label=None):
    """
    Generate a visual representation of progress.
    """
    bar = []
    if label is not None:
        bar.append(label)
    pvalue = parse_number(value)
    pmaximum = parse_number(maximum)

    used = int(width*pvalue/pmaximum)
    if used > pmaximum:
        used = width
    elif used < 0:
        used = 0
    unused = width - used
    bar.extend(['[', '|'*used, '.'*unused, ']'])

    if show_value:
        bar.append(' {value}/{max}'.format(value=value, max=maximum))

    return "".join(bar)


def numeric_sort(name):
    """
    Pull all digits from the name and make a list with all number in it.
    """
    return [int(x) for x in re.findall(r'[0-9]+', name)]

def squeue(options):
    """Process squeue and print formatted output to terminal."""
    cluster="gpsc5"
    # Get data
    jobs = squeuef_local()
    #for key in ['jobs', 'last_backfill', 'last_update', 'meta', 'errors', 'warnings']:
        #print(f"\n\n\n*****{key}*****\n\n\n\n")
        #print(jobs[cluster][key])

# ['account', 'accrue_time', 'admin_comment', 'allocating_node', 'array_job_id', 'array_task_id', 'array_max_tasks', 'array_task_string', 'association_id', 'batch_features', 'batch_flag', 'batch_host', 'flags', 'burst_buffer', 'burst_buffer_state', 'cluster', 'cluster_features', 'command', 'comment', 'container', 'container_id', 'contiguous', 'core_spec', 'thread_spec', 'cores_per_socket', 'billable_tres', 'cpus_per_task', 'cpu_frequency_minimum', 'cpu_frequency_maximum', 'cpu_frequency_governor', 'cpus_per_tres', 'cron', 'deadline', 'delay_boot', 'dependency', 'derived_exit_code', 'eligible_time', 'end_time', 'excluded_nodes', 'exit_code', 'extra', 'failed_node', 'features', 'federation_origin', 'federation_siblings_active', 'federation_siblings_viable', 'gres_detail', 'group_id', 'group_name', 'het_job_id', 'het_job_id_set', 'het_job_offset', 'job_id', 'job_resources', 'job_size_str', 'job_state', 'last_sched_evaluation', 'licenses', 'mail_type', 'mail_user', 'max_cpus', 'max_nodes', 'mcs_label', 'memory_per_tres', 'name', 'network', 'nodes', 'nice', 'tasks_per_core', 'tasks_per_tres', 'tasks_per_node', 'tasks_per_socket', 'tasks_per_board', 'cpus', 'node_count', 'tasks', 'partition', 'prefer', 'memory_per_cpu', 'memory_per_node', 'minimum_cpus_per_node', 'minimum_tmp_disk_per_node', 'power', 'preempt_time', 'preemptable_time', 'pre_sus_time', 'hold', 'priority', 'profile', 'qos', 'reboot', 'required_nodes', 'minimum_switches', 'requeue', 'resize_time', 'restart_cnt', 'resv_name', 'scheduled_nodes', 'selinux_context', 'shared', 'exclusive', 'oversubscribe', 'show_flags', 'sockets_per_board', 'sockets_per_node', 'start_time', 'state_description', 'state_reason', 'standard_error', 'standard_input', 'standard_output', 'submit_time', 'suspend_time', 'system_comment', 'time_limit', 'time_minimum', 'threads_per_core', 'tres_bind', 'tres_freq', 'tres_per_job', 'tres_per_node', 'tres_per_socket', 'tres_per_task', 'tres_req_str', 'tres_alloc_str', 'user_id', 'user_name', 'maximum_switch_wait_time', 'wckey', 'current_working_directory']
    #for job in jobs[cluster]['jobs']:
    #    print(f"user name: {job['user_name']}")
    #    print(f"tres per node: {job['tres_per_node']}")
    #    print(f"tasks per node: {job['tasks_per_node']}")
    #    print(f"tasks: {job['tasks']}")
    #    print(f"nodes: {job['nodes']}")
    
    nodes = sinfof_local()
    for info in nodes[cluster]['sinfo']:
        # dict_keys(['port', 'node', 'nodes', 'cpus', 'sockets', 'cores', 'threads', 'disk', 'memory', 'weight', 'features', 'gres', 'cluster', 'comment', 'extra', 'reason', 'reservation', 'partition'])
        
        # 'cpus' {'allocated': 0, 'idle': 40, 'other': 0, 'total': 40, 'minimum': 40, 'maximum': 40, 'load': {'minimum': 0, 'maximum': 0}, 'per_node': {'max': {'set': True, 'infinite': False, 'number': 40}}}
        # 'nodes' {'allocated': 0, 'idle': 1, 'other': 0, 'total': 1, 'hostnames': [], 'addresses': [], 'nodes': ['ib12ln-007']}
        # 'gres' {'total': 'gpu:tesla_v100-sxm2-16gb:4(S:0)', 'used': 'gpu:tesla_v100-sxm2-16gb:1(IDX:0)'}
        # 'cores' {'minimum': 18, 'maximum': 18} <--- not sure if that's used?
        #
        print(info['cores'])
        print(f"Node: {info['nodes']['nodes'][0]} allocated {info['cpus']['allocated']} idle {info['cpus']['idle']} total {info['cpus']['total']}")

def qstat_priority(options):
    """Process qstat and print formatted output to terminal."""

    # Get data
    jobs = qstat()

    # Use regular expressions to prune the job list
    if options.user is not None:
        user_regexes = [re.compile('^{0}$'.format(user_regex))
                        for user_regex in options.user]
        jobs = [job for job in jobs if
                any(user_regex.match(job['JB_owner'])
                    for user_regex in user_regexes)]

    # are there job arrays?
    task_width = max([len(job.get('tasks', '')) for job in jobs] + [0])
    if task_width > 0:
        task_width += 1
        task_str = ' tasks'
    else:
        task_str = ''

    # how wide? include 8 for empty case so header looks reasonable
    name_width = max([8] + [len(job['JB_name']) for job in jobs])

    # header              "xky        "      job age             t
    print("job-ID   prior      user          state  run/wait time       queue"
          "            slots  {1:{0}}{2}"
          "".format(name_width, 'name', task_str))
    print("—"*(85+name_width+task_width))

    # Get rid of the microseconds so that the output is only reported to the
    # second
    now = datetime.now().replace(microsecond=0)

    # Track if we are in pending jobs to add a separator
    pending_break = False
    for job in jobs:
        if not pending_break and 'q' in job['state']:
            print("—"*(85+name_width+task_width))
            pending_break = True

        # Parse the dates into deltas -> more useful?
        try:
            runtime = now - parse(job['JAT_start_time'])
        except KeyError:
            runtime = now - parse(job['JB_submission_time'])

        # non running jobs have no queue
        if job['queue_name'] is not None:
            if options.queue:
                queue = job['queue_name']
            else:
                queue = job['queue_name'].split('@')[1].split('.')[0]
        else:
            queue = ''

        # job_array?
        if 'tasks' in job:
            tasks = ' ' + job['tasks']
        else:
            tasks = ''

        print("{0[JB_job_number]:<7s}  {0[JAT_prio]:<9s}  {0[JB_owner]:<12}  "
              "{0[state]:<5s}  {runtime:>18s}  {queue:<15}  {0[slots]:>5}  "
              "{0[JB_name]:<{name_width}s}{tasks:<s}"
              "".format(job, runtime=runtime, queue=queue,
                        name_width=name_width, tasks=tasks))

    return


def qstat_full(options):
    """
    Process jobs and arrange like 'qstst -f', but nicer.
    """

    all_queues, users, jobs = qstatf()

    # Use regular expressions to prune the job list
    if options.user is not None:
        user_regexes = [re.compile('^{0}$'.format(user_regex))
                        for user_regex in options.user]
        jobs = [job for job in jobs if
                any(user_regex.match(job['JB_owner'])
                    for user_regex in user_regexes)]

    # are there job arrays?
    task_width = max([len(job.get('tasks', '')) for job in jobs] + [0])
    if task_width > 0:
        task_width += 1
        task_str = ' tasks'
    else:
        task_str = ''

    # how wide? include 8 for empty case so header looks reasonable
    name_width = max([8] + [len(job['JB_name']) for job in jobs])

    # header
    print("job-ID   prior      user          state  run/wait time       queue"
          "            slots  {1:{0}}{2}"
          "".format(name_width, 'name', task_str))

    # Get rid of the microseconds so that the output is only reported to the
    # second
    now = datetime.now().replace(microsecond=0)

    # Setup how people's jobs look:
    if options.colour:
        this_user = {getuser():
                     "\033[104;39;1m{user:<12}\033[0m".format(user=getuser())}
        usercodes = ColourDict(width=12, mapping=this_user)
        queues = ColourDict(width=15)
    else:
        usercodes = AutoDict(width=12)
        queues = AutoDict(width=15)

    jobfmt = ("{0[JB_job_number]:<7s}  {0[JAT_prio]:<9s}  {user}  "
              "{0[state]:<5s}  {runtime:>18s}  {queue}  {0[slots]:>5}  "
              "{0[JB_name]:<{name_width}s}{tasks:<s}")

    for node in sorted(all_queues, key=numeric_sort):
        info = all_queues[node]
        print("—"*(85+name_width+task_width))
        #print(all_queues[node]['resource'])

        nodestr = ["\033[1m>> {node:10} ".format(node=node, nodeinfo=info),
                   progressbar(info['slots_used'],
                               info['slots_total'],
                               width=int(info['slots_total']),
                               label='Slots:  ')]
        if 'load_avg' in info['resource']:
            nodestr.append('Load: {0:.2f}'.format(
                float(info['resource']['load_avg'])))
        if 'mem_total' in info['resource']:
            nodestr.append(progressbar(
                info['resource'].get('mem_used', '0.0 G'),
                info['resource']['mem_total'],
                width=20, label="\n>>              Memory: "))
        print("  ".join(nodestr) + "\033[38;0m")

        for job in jobs:
            if 'node' in job and job['node'] == node:
                user = usercodes[job['JB_owner']]
                runtime = now - parse(job['JAT_start_time'])
                queue = queues[job['JB_queue'].split('@')[0]]
                if 'tasks' in job:
                    tasks = ' ' + job['tasks']
                else:
                    tasks = ''
                print(jobfmt.format(job, user=user, runtime=runtime,
                                    queue=queue, tasks=tasks,
                                    name_width=name_width))

    print("—"*(85+name_width+task_width))
    print(" Pending jobs ")
    print("—"*(85+name_width+task_width))
    for job in jobs:
        if 'q' in job['state']:
            user = usercodes[job['JB_owner']]
            runtime = now - parse(job['JB_submission_time'])
            queue = ' '*15  # Expects 15 wide (ansi codes excepted)
            if 'tasks' in job:
                tasks = ' ' + job['tasks']
            else:
                tasks = ''
            print(jobfmt.format(job, user=user, runtime=runtime, queue=queue,
                                tasks=tasks, name_width=name_width))

    return


def main():
    """Process options and call the qstat formatting code."""
    options = commandline()
    squeue(options)

    #if options.full:
    #    qstat_full(options)
    #else:
    #    qstat_priority(options)


if __name__ == '__main__':
    main()
